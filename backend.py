
# -*- coding: utf-8 -*-
"""Draft.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JeEXxTzKYwB_uraxC4vlsq6IwYfs1qhh
"""

import getpass
import os
import logging
logging.getLogger("langchain_google_genai.chat_models").setLevel(logging.ERROR)
if "GOOGLE_API_KEY" not in os.environ:
    os.environ["GOOGLE_API_KEY"] = "AIzaSyD_K258YPnc7_GuDDtQ5kHFfe4SO2cmpYY"
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI

from langchain_google_genai import GoogleGenerativeAIEmbeddings
import chromadb
# 1) Kh·ªüi raw embedder cho Gemini text-embedding-004 (768-dim)
raw_embedder = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")

# 2) Wrapper ƒë√∫ng interface (tham s·ªë ph·∫£i t√™n ‚Äúinput‚Äù)aa
class ChromaEmbeddingWrapper768:
    def __init__(self, embedder, name: str):
        self.embedder = embedder
        self._name = name

    def __call__(self, input: list[str]) -> list[list[float]]:
        # ChromaDB s·∫Ω g·ªçi wrapper(self, input)
        return self.embedder.embed_documents(input)

    def name(self) -> str:
        return self._name

# T·∫°o instance wrapper
wrapper_768 = ChromaEmbeddingWrapper768(
    raw_embedder,
    name="text-embedding-004"   # t√™n model embedding ch√≠nh x√°c
)

# 3) K·∫øt n·ªëi Chroma
client = chromadb.Client()

pdf_collection = client.get_or_create_collection(
    name="pdf_auto_khdl",
    embedding_function=wrapper_768
)
excel_collection = client.get_or_create_collection(
    name="excel_manual_khdl",
    embedding_function=wrapper_768
)

pdf_folder = "./BKI/Auto chunk"
pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith(".pdf")]

#Auto chunking
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import (
TextLoader,
UnstructuredPDFLoader,
PyPDFLoader
)
from langchain_google_genai import GoogleGenerativeAIEmbeddings
splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,             # tƒÉng l√™n ƒë·ªÉ ch·ª©a ƒë·ªß 1-2 ƒëo·∫°n √Ω li·ªÅn m·∫°ch
    chunk_overlap=100,          # v·ª´a ph·∫£i, ƒë·ªß ƒë·ªÉ kh√¥ng m·∫•t ng·ªØ c·∫£nh
    separators=["\n\n", "\n", ".", "!", "?", " ", ""]
)
for file in pdf_files:
    file_path = os.path.join(pdf_folder, file)  #l·∫•y ƒë·ªãa ch·ªâ c·ª• th·ªÉ c·ªßa t·ª´ng file trong folder
    loader = PyPDFLoader(file_path)
    pages = loader.load()  # M·ªói trang l√† 1 Document

    full_text = "\n".join([page.page_content for page in pages])#N·ªëi c√°c trang trong file th√†nh m·ªôt ƒëo·∫°n
    chunks = splitter.split_text(full_text)  # ‚Üí list[str]
    doc_id_base = "to_roi_KHDL_BMT_2025" # T√™n file kh√¥ng ƒëu√¥i

    documents = os.path.splitext(file)[0]
    metadatas = [{"source": doc_id_base, "content": chunk} for chunk in chunks]
    to_embed = [f"{documents} ‚Äî {meta['content']}" for meta in metadatas]
    embeddings = raw_embedder.embed_documents(to_embed)
    ids = [f"{documents}_chunk_{i}" for i in range(len(chunks))]
     # N·∫°p v√†o collection
    pdf_collection.add(
        documents=[documents] * len(chunks),  # t√™n file l·∫∑p l·∫°i
        metadatas=metadatas,
        embeddings=embeddings,
        ids=ids
    )

#Manual chunking
import pandas as pd
from langchain_google_genai import GoogleGenerativeAIEmbeddings

# ƒê·ªçc Excel
df = pd.read_excel("./BKI/Manual chunk/Data.xlsx")  # Ho·∫∑c ƒë√∫ng ƒë∆∞·ªùng d·∫´n Colab c·ªßa b·∫°n

# H√†m x·ª≠ l√Ω g·∫°ch ƒë·∫ßu d√≤ng n·∫øu c·∫ßn (kh√¥ng b·∫Øt bu·ªôc)
def format_bullets(raw: str) -> str:
    items = [s.strip() for s in str(raw).split(";") if s.strip()]
    return "\n".join(f"+ {it}" for it in items)

for idx, row in df.iterrows():
    # a) T·∫°o document (ti√™u ƒë·ªÅ) v√† content (n·ªôi dung ƒë√£ format)
    documents = f"- {row['Doccument']}".strip()
    content = format_bullets(row["Content"])
    source = str(row["Source"])
    to_embed = [f"{documents} ‚Äî {content}"]

    # b) Embed ngay chu·ªói ƒë√≥ (list ƒë·ªô d√†i = 1)
    embedding = raw_embedder.embed_documents(to_embed)

    # c) Add v√†o collection
    excel_collection.add(
        documents=[documents],
        metadatas=[{"source": source, "content": content}],
        embeddings=embedding,
        ids=[f"doc{idx+1}"]
    )

#t√≠nh c√°c ƒëi·ªÉm th√†nh ph·∫ßn ƒë·ªÉ t√≠nh ƒëi·ªÉm h·ªçc l·ª±c
def calculate_nang_luc(math_score: float, other_score_sum: float) -> dict:
    """
    ƒêi·ªÉm nƒÉng l·ª±c = (math_score * 2 + other_score_sum) / 15
    """
    weighted = math_score * 2 + other_score_sum
    nang_luc = round(weighted / 15, 2)
    return {"nang_luc_score": nang_luc}


def calculate_thpt_test_converted(total_three_subjects: float) -> dict:
    """
    ƒêi·ªÉm TNTHPT quy ƒë·ªïi = (T·ªïng ƒëi·ªÉm thi 3 m√¥n) / 3 * 10
    """
    converted = round(total_three_subjects / 3 * 10, 2)
    return {"thpt_test_converted": converted}


def calculate_hocba_converted(avg_grade_three_years: float) -> dict:
    """
    ƒêi·ªÉm h·ªçc THPT quy ƒë·ªïi = Trung b√¨nh c·ªông ƒëi·ªÉm TB 3 nƒÉm √ó 10
    """
    converted = round(avg_grade_three_years * 10, 2)
    return {"hocba_converted": converted}

#t√≠nh ƒëi·ªÉm h·ªçc l·ª±c
def calculate_academic_score(math_score: float,
                             other_score_sum: float,
                             total_three_subjects: float,
                             avg_grade_three_years: float) -> dict:
    """
    ƒêi·ªÉm h·ªçc l·ª±c = ƒêi·ªÉm nƒÉng l·ª±c * 0.7
                 + ƒêi·ªÉm TNTHPT quy ƒë·ªïi * 0.2
                 + ƒêi·ªÉm h·ªçc THPT quy ƒë·ªïi * 0.1
    Tr·∫£ v·ªÅ dict bao g·ªìm c√°c gi√° tr·ªã trung gian v√† k·∫øt qu·∫£ cu·ªëi.
    """
    # G·ªçi c√°c h√†m con ƒë√£ ƒë·ªãnh nghƒ©a tr∆∞·ªõc
    nang_luc = calculate_nang_luc(math_score, other_score_sum)["nang_luc_score"]
    thpt_converted = calculate_thpt_test_converted(total_three_subjects)["thpt_test_converted"]
    hocba_converted = calculate_hocba_converted(avg_grade_three_years)["hocba_converted"]

    # T√≠nh ƒêi·ªÉm h·ªçc l·ª±c theo t·ª∑ l·ªá
    academic = round(nang_luc * 0.7 + thpt_converted * 0.2 + hocba_converted * 0.1, 2)

    return {
        "academic_score": academic,
        "nang_luc_score": nang_luc,
        "thpt_test_converted": thpt_converted,
        "hocba_converted": hocba_converted
    }

#t√≠nh ƒëi·ªÉm c·ªông
def calculate_bonus(academic_score: float,
                    performance_bonus: float) -> dict:
    """
    - Gi·ªõi h·∫°n performance_bonus t·ªëi ƒëa 10.
    - N·∫øu academic_score + raw_bonus < 100 -> bonus = raw_bonus
      Ng∆∞·ª£c l·∫°i -> bonus = 100 - academic_score
    """
    raw_bonus = min(performance_bonus, 10.0)
    if academic_score + raw_bonus < 100.0:
        bonus = raw_bonus
    else:
        bonus = max(0.0, 100.0 - academic_score)
    return {"bonus": round(bonus, 2)}

#t√≠nh ƒëi·ªÉm ∆∞u ti√™n
def calculate_priority(academic_score: float,
                       bonus: float,
                       priority_group_score: float) -> dict:
    """
    - priority_converted = (priority_group_score / 3) * 10
    - N·∫øu academic_score + bonus < 75 -> priority = priority_converted
      Ng∆∞·ª£c l·∫°i -> priority = ((100 - academic_score - bonus)/25) * priority_converted
    - L√†m tr√≤n 2 ch·ªØ s·ªë
    """
    priority_converted = (priority_group_score / 3.0) * 10.0
    if academic_score + bonus < 75.0:
        priority = priority_converted
    else:
        priority = round((100.0 - academic_score - bonus) / 25.0 * priority_converted, 2)
    return {"priority": round(priority, 2)}

#t√≠nh ƒëi·ªÉm x√©t tuy·ªÉn
def calculate_admission_score(math_score: float,
                              other_score_sum: float,
                              total_three_subjects: float,
                              avg_grade_three_years: float,
                              performance_bonus: float,
                              priority_group_score: float) -> dict:
    """
    T√≠nh ƒêi·ªÉm x√©t tuy·ªÉn tr√™n thang 100 bao g·ªìm:
      1) ƒêi·ªÉm h·ªçc l·ª±c (70% nƒÉng l·ª±c + 20% TNTHPT quy ƒë·ªïi + 10% h·ªçc b·∫° quy ƒë·ªïi)
      2) ƒêi·ªÉm c·ªông th√†nh t√≠ch (t·ªëi ƒëa 10, kh√¥ng v∆∞·ª£t 100)
      3) ƒêi·ªÉm ∆∞u ti√™n (quy ƒë·ªïi & ƒëi·ªÅu ch·ªânh theo <75 / ‚â•75)
    Tr·∫£ v·ªÅ dict v·ªõi:
      - academic_score, bonus, priority, admission_score
      - c√πng c√°c ƒëi·ªÉm trung gian: nang_luc_score, thpt_test_converted, hocba_converted
    """
    # 1) Academic score
    acad = calculate_academic_score(
        math_score, other_score_sum,
        total_three_subjects, avg_grade_three_years
    )
    academic_score = acad["academic_score"]

    # 2) Bonus
    bonus = calculate_bonus(academic_score, performance_bonus)["bonus"]

    # 3) Priority
    priority = calculate_priority(academic_score, bonus, priority_group_score)["priority"]

    # 4) Total admission score
    admission_score = round(academic_score + bonus + priority, 2)

    return {
        "admission_score": admission_score,
        "academic_score": academic_score,
        "nang_luc_score": acad["nang_luc_score"],
        "thpt_test_converted": acad["thpt_test_converted"],
        "hocba_converted": acad["hocba_converted"],
        "bonus": bonus,
        "priority": priority
    }

# ƒê·ªãnh nghƒ©a c√°c Tool s·ª≠ d·ª•ng c√°c h√†m c√≥ s·∫µn
from langchain.tools import Tool
tools = [
    Tool(
        name="calculate_nang_luc",
        func=calculate_nang_luc,
        description="T√≠nh ƒêi·ªÉm nƒÉng l·ª±c = (math_score * 2 + other_score_sum) / 15",
        args_schema={
            "math_score": {"type": "number", "description": "ƒêi·ªÉm ƒêGNL m√¥n To√°n", "required": True},
            "other_score_sum": {"type": "number", "description": "T·ªïng ƒëi·ªÉm ƒêGNL c√°c m√¥n c√≤n l·∫°i", "required": True}
        }
    ),
    Tool(
        name="calculate_hocba_converted",
        func=calculate_hocba_converted,
        description="T√≠nh ƒêi·ªÉm h·ªçc THPT quy ƒë·ªïi = Trung b√¨nh c·ªông ƒëi·ªÉm TB 3 nƒÉm √ó 10.",
        args_schema={
            "avg_grade_three_years": {"type": "number", "description": "Trung b√¨nh c·ªông ƒëi·ªÉm TB l·ªõp 10, 11, 12 c·ªßa c√°c m√¥n trong t·ªï h·ª£p", "required": True}
        }
    ),
    Tool(
        name="calculate_thpt_test_converted",
        func=calculate_thpt_test_converted,
        description="T√≠nh ƒêi·ªÉm TNTHPT quy ƒë·ªïi = (T·ªïng ƒëi·ªÉm thi 3 m√¥n trong t·ªï h·ª£p) / 3 √ó 10.",
        args_schema={
            "total_three_subjects": {"type": "number", "description": "T·ªïng ƒëi·ªÉm thi THPT c·ªßa 3 m√¥n trong t·ªï h·ª£p", "required": True}
        }
    ),
    Tool(
        name="calculate_academic_score",
        func=calculate_academic_score,
        description="T√≠nh ƒêi·ªÉm h·ªçc l·ª±c tr√™n thang 100: 70% t·ª´ ƒêi·ªÉm nƒÉng l·ª±c, 20% t·ª´ ƒêi·ªÉm TNTHPT quy ƒë·ªïi, 10% t·ª´ ƒêi·ªÉm h·ªçc b·∫° quy ƒë·ªïi.",
        args_schema={
            "math_score": {"type": "number", "description": "ƒêi·ªÉm ƒêGNL m√¥n To√°n", "required": True},
            "other_score_sum": {"type": "number", "description": "T·ªïng ƒëi·ªÉm ƒêGNL c√°c m√¥n c√≤n l·∫°i", "required": True},
            "total_three_subjects": {"type": "number", "description": "T·ªïng ƒëi·ªÉm thi THPT c·ªßa 3 m√¥n trong t·ªï h·ª£p", "required": True},
            "avg_grade_three_years": {"type": "number", "description": "Trung b√¨nh c·ªông ƒëi·ªÉm TB 3 nƒÉm c√°c m√¥n trong t·ªï h·ª£p", "required": True}
        }
    ),
    Tool(
        name="calculate_bonus",
        func=calculate_bonus,
        description="T√≠nh ƒêi·ªÉm c·ªông th√†nh t√≠ch (t·ªëi ƒëa 10 ƒëi·ªÉm, kh√¥ng v∆∞·ª£t 100 ƒëi·ªÉm khi c·ªông v·ªõi ƒêi·ªÉm h·ªçc l·ª±c).",
        args_schema={
            "academic_score": {"type": "number", "description": "ƒêi·ªÉm h·ªçc l·ª±c tr√™n thang 100", "required": True},
            "performance_bonus": {"type": "number", "description": "T·ªïng ƒëi·ªÉm c·ªông th√†nh t√≠ch ban ƒë·∫ßu (t·ªëi ƒëa 10)", "required": True}
        }
    ),
    Tool(
        name="calculate_priority",
        func=calculate_priority,
        description="T√≠nh ƒêi·ªÉm ∆∞u ti√™n theo quy t·∫Øc: n·∫øu academic_score+bonus <75 d√πng nguy√™n, ng∆∞·ª£c l·∫°i ph·∫£i ƒëi·ªÅu ch·ªânh.",
        args_schema={
            "academic_score": {"type": "number", "description": "ƒêi·ªÉm h·ªçc l·ª±c ƒë√£ t√≠nh", "required": True},
            "bonus": {"type": "number", "description": "ƒêi·ªÉm c·ªông th√†nh t√≠ch ƒë√£ ƒëi·ªÅu ch·ªânh", "required": True},
            "priority_group_score": {"type": "number", "description": "ƒêi·ªÉm ∆∞u ti√™n (khu v·ª±c/ƒë·ªëi t∆∞·ª£ng) ban ƒë·∫ßu tr√™n thang 0‚Äì2.75", "required": True}
        }
    ),
    Tool(
        name="calculate_admission_score",
        func=calculate_admission_score,
        description="T√≠nh ƒêi·ªÉm x√©t tuy·ªÉn tr√™n thang 100, g·ªôp ƒëi·ªÉm h·ªçc l·ª±c, ƒëi·ªÉm c·ªông th√†nh t√≠ch v√† ƒëi·ªÉm ∆∞u ti√™n.",
        args_schema={
            "math_score": {"type": "number", "description": "ƒêi·ªÉm ƒêGNL m√¥n To√°n", "required": True},
            "other_score_sum": {"type": "number", "description": "T·ªïng ƒëi·ªÉm ƒêGNL c√°c m√¥n c√≤n l·∫°i", "required": True},
            "total_three_subjects": {"type": "number", "description": "T·ªïng ƒëi·ªÉm thi THPT c·ªßa 3 m√¥n trong t·ªï h·ª£p", "required": True},
            "avg_grade_three_years": {"type": "number", "description": "Trung b√¨nh c·ªông ƒëi·ªÉm TB l·ªõp 10,11,12 c√°c m√¥n trong t·ªï h·ª£p", "required": True},
            "performance_bonus": {"type": "number", "description": "ƒêi·ªÉm c·ªông th√†nh t√≠ch ban ƒë·∫ßu (t·ªëi ƒëa 10)", "required": True},
            "priority_group_score": {"type": "number", "description": "ƒêi·ªÉm ∆∞u ti√™n (khu v·ª±c/ƒë·ªëi t∆∞·ª£ng) ban ƒë·∫ßu tr√™n thang 0‚Äì2.75", "required": True}
        }
    )
]

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash-lite-preview-06-17",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
    # other params...
)

from langchain.schema import Document, HumanMessage, SystemMessage, AIMessage
import re
# H√†m truy v·∫•n ChromaDB
def query_chroma(collection, query: str, top_k: int = 3) -> list[dict]:
    # Embed c√¢u h·ªèi
    query_embedding = raw_embedder.embed_query(query)

    # Truy v·∫•n collection
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k
    )

    # Format k·∫øt qu·∫£
    return [
        [doc, {"content": meta["content"]}]
        for doc, meta in zip(results["documents"][0], results["metadatas"][0])
    ]
def process_function_call(query: str, llm_with_tools) -> str:
    # System Prompt r√µ r√†ng v·ªõi v√≠ d·ª• c·ª• th·ªÉ messages

    messages = [
        SystemMessage(content="""
        B·∫°n l√† chatbot t√≠nh to√°n ƒëi·ªÉm tuy·ªÉn sinh. Nhi·ªám v·ª•: nh·∫≠n di·ªán c√¥ng c·ª• ph√π h·ª£p v√† tr√≠ch xu·∫•t tham s·ªë ch√≠nh x√°c t·ª´ c√¢u h·ªèi.

        H∆∞·ªõng d·∫´n:
        - X√°c ƒë·ªãnh c√¥ng c·ª• d·ª±a tr√™n th√¥ng tin trong c√¢u h·ªèi.
        - Tr√≠ch xu·∫•t tham s·ªë theo t√™n ch√≠nh x√°c: math_score_ other_score_sum, total_three_subjects, avg_grade_three_years, performance_bonus, priority_group_score.
        - N·∫øu thi·∫øu tham s·ªë, tr·∫£ v·ªÅ th√¥ng b√°o y√™u c·∫ßu cung c·∫•p ƒë·ªß th√¥ng tin.

        V√≠ d·ª•:
        1. 'T√≠nh ƒëi·ªÉm nƒÉng l·ª±c v·ªõi ƒëi·ªÉm To√°n 8.5 v√† t·ªïng c√°c m√¥n kh√°c 16'
           ‚Üí C√¥ng c·ª•: calculate_nang_luc, tham s·ªë: math_score=8.5, other_score_sum=16.0
        2. 'T√≠nh ƒëi·ªÉm thi t·ªët nghi·ªáp quy ƒë·ªïi v·ªõi t·ªïng ƒëi·ªÉm 3 m√¥n l√† 27'
           ‚Üí C√¥ng c·ª•: calculate_thpt_test_converted, tham s·ªë: total_three_subjects=27.0
        3. 'T√≠nh ƒëi·ªÉm h·ªçc b·∫° quy ƒë·ªïi v·ªõi trung b√¨nh 3 nƒÉm l√† 8.5'
           ‚Üí C√¥ng c·ª•: calculate_hocba_converted, tham s·ªë: avg_grade_three_years=8.5
        4. 'T√≠nh ƒëi·ªÉm h·ªçc l·ª±c v·ªõi ƒëi·ªÉm To√°n 8, t·ªïng c√°c m√¥n kh√°c 15, t·ªïng ƒëi·ªÉm thi THPT 24, trung b√¨nh 3 nƒÉm 8'
           ‚Üí C√¥ng c·ª•: calculate_academic_score, tham s·ªë: math_score=8.0, other_score_sum=15.0, total_three_subjects=24.0, avg_grade_three_years=8.0
        5. 'T√≠nh ƒëi·ªÉm c·ªông v·ªõi ƒëi·ªÉm h·ªçc l·ª±c 80 v√† ƒëi·ªÉm th√†nh t√≠ch 5'
           ‚Üí C√¥ng c·ª•: calculate_bonus, tham s·ªë: academic_score=80.0, performance_bonus=5.0
        6. 'T√≠nh ƒëi·ªÉm ∆∞u ti√™n v·ªõi ƒëi·ªÉm h·ªçc l·ª±c 80, ƒëi·ªÉm th√†nh t√≠ch 5, ƒëi·ªÉm ∆∞u ti√™n nh√≥m 2'
           ‚Üí C√¥ng c·ª•: calculate_priority, tham s·ªë: academic_score=80.0, bonus=5.0, priority_group_score=2.0
        7. 'T√≠nh ƒëi·ªÉm x√©t tuy·ªÉn v·ªõi ƒëi·ªÉm To√°n 8, t·ªïng c√°c m√¥n kh√°c 15, t·ªïng ƒëi·ªÉm thi THPT 24, trung b√¨nh 3 nƒÉm 8, ƒëi·ªÉm th√†nh t√≠ch 5, ƒëi·ªÉm ∆∞u ti√™n nh√≥m 2'
           ‚Üí C√¥ng c·ª•: calculate_admission_score, tham s·ªë: math_score=8.0, other_score_sum=15.0, total_three_subjects=24.0, avg_grade_three_years=8.0, performance_bonus=5.0, priority_group_score=2.0

        N·∫øu kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c ƒë·ªß tham s·ªë, tr·∫£ v·ªÅ: 'Vui l√≤ng cung c·∫•p ƒë·ªß th√¥ng tin (v√≠ d·ª•: ƒëi·ªÉm To√°n, t·ªïng ƒëi·ªÉm c√°c m√¥n kh√°c, t·ªïng ƒëi·ªÉm thi THPT, trung b√¨nh 3 nƒÉm, ƒëi·ªÉm th√†nh t√≠ch, ƒëi·ªÉm ∆∞u ti√™n).'
        """),
        HumanMessage(content=query)
    ]

    response = llm_with_tools.invoke(messages)

    if response.tool_calls:
        tool_call = response.tool_calls[0]
        tool_name = tool_call['name']
        tool_args = tool_call['args']

        # T√¨m c√¥ng c·ª• t∆∞∆°ng ·ª©ng
        for tool in tools:
            if tool.name == tool_name:
                # L·∫•y danh s√°ch tham s·ªë b·∫Øt bu·ªôc t·ª´ args_schema
                required_params = tool.args_schema.get("required", []) if isinstance(tool.args_schema, dict) else []

                # Ki·ªÉm tra xem c√≥ ƒë·ªß tham s·ªë kh√¥ng
                if not tool_args or not all(param in tool_args for param in required_params):
                    query_lower = query.lower()
                    tool_args = {}

                    if tool_name == "calculate_nang_luc":
                        math_match = re.search(r"ƒëi·ªÉm\s*to√°n\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        other_match = re.search(r"t·ªïng\s*(?:ƒëi·ªÉm\s*)?c√°c\s*m√¥n\s*kh√°c\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        if math_match and other_match:
                            tool_args = {
                                "math_score": float(math_match.group(1)),
                                "other_score_sum": float(other_match.group(1))
                            }
                    elif tool_name == "calculate_thpt_test_converted":
                        score_match = re.search(r"t·ªïng\s*ƒëi·ªÉm\s*(?:thi\s*)?(?:ba\s*m√¥n)?\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        if score_match:
                            tool_args = {"total_three_subjects": float(score_match.group(1))}
                    elif tool_name == "calculate_hocba_converted":
                        avg_match = re.search(r"trung\s*b√¨nh\s*3\s*nƒÉm\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        if avg_match:
                            tool_args = {"avg_grade_three_years": float(avg_match.group(1))}
                    elif tool_name == "calculate_academic_score":
                        math_match = re.search(r"ƒëi·ªÉm\s*to√°n\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        other_match = re.search(r"t·ªïng\s*(?:ƒëi·ªÉm\s*)?c√°c\s*m√¥n\s*kh√°c\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        thpt_match = re.search(r"t·ªïng\s*ƒëi·ªÉm\s*thi\s*thpt\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        avg_match = re.search(r"trung\s*b√¨nh\s*3\s*nƒÉm\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        if all([math_match, other_match, thpt_match, avg_match]):
                            tool_args = {
                                "math_score": float(math_match.group(1)),
                                "other_score_sum": float(other_match.group(1)),
                                "total_three_subjects": float(thpt_match.group(1)),
                                "avg_grade_three_years": float(avg_match.group(1))
                            }
                    elif tool_name == "calculate_bonus":
                        academic_match = re.search(r"ƒëi·ªÉm\s*h·ªçc\s*l·ª±c\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        bonus_match = re.search(r"ƒëi·ªÉm\s*th√†nh\s*t√≠ch\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        if academic_match and bonus_match:
                            tool_args = {
                                "academic_score": float(academic_match.group(1)),
                                "performance_bonus": float(bonus_match.group(1))
                            }
                    elif tool_name == "calculate_priority":
                        academic_match = re.search(r"ƒëi·ªÉm\s*h·ªçc\s*l·ª±c\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        bonus_match = re.search(r"ƒëi·ªÉm\s*th√†nh\s*t√≠ch\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        priority_match = re.search(r"ƒëi·ªÉm\s*∆∞u\s*ti√™n\s*(?:nh√≥m)?\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        if all([academic_match, bonus_match, priority_match]):
                            tool_args = {
                                "academic_score": float(academic_match.group(1)),
                                "bonus": float(bonus_match.group(1)),
                                "priority_group_score": float(priority_match.group(1))
                            }
                    elif tool_name == "calculate_admission_score":
                        math_match = re.search(r"ƒëi·ªÉm\s*to√°n\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        other_match = re.search(r"t·ªïng\s*(?:ƒëi·ªÉm\s*)?c√°c\s*m√¥n\s*kh√°c\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        thpt_match = re.search(r"t·ªïng\s*ƒëi·ªÉm\s*thi\s*thpt\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        avg_match = re.search(r"trung\s*b√¨nh\s*3\s*nƒÉm\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        bonus_match = re.search(r"ƒëi·ªÉm\s*th√†nh\s*t√≠ch\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        priority_match = re.search(r"ƒëi·ªÉm\s*∆∞u\s*ti√™n\s*(?:nh√≥m)?\s*[=:]?\s*(\d+\.?\d*)", query_lower)
                        if all([math_match, other_match, thpt_match, avg_match, bonus_match, priority_match]):
                            tool_args = {
                                "math_score": float(math_match.group(1)),
                                "other_score_sum": float(other_match.group(1)),
                                "total_three_subjects": float(thpt_match.group(1)),
                                "avg_grade_three_years": float(avg_match.group(1)),
                                "performance_bonus": float(bonus_match.group(1)),
                                "priority_group_score": float(priority_match.group(1))
                            }

                try:
                    # Ki·ªÉm tra xem t·∫•t c·∫£ tham s·ªë b·∫Øt bu·ªôc c√≥ trong tool_args kh√¥ng
                    if tool_args and all(param in tool_args for param in required_params):
                        result = tool.func(**tool_args)
                        if tool_name == "calculate_nang_luc":
                            return f"ƒêi·ªÉm nƒÉng l·ª±c: {result['nang_luc_score']}"
                        elif tool_name == "calculate_thpt_test_converted":
                            return f"ƒêi·ªÉm thi THPT quy ƒë·ªïi: {result['thpt_test_converted']}"
                        elif tool_name == "calculate_hocba_converted":
                            return f"ƒêi·ªÉm h·ªçc b·∫° quy ƒë·ªïi: {result['hocba_converted']}"
                        elif tool_name == "calculate_academic_score":
                            return (f"ƒêi·ªÉm h·ªçc l·ª±c: {result['academic_score']}\n"
                                    f"Chi ti·∫øt: ƒêi·ªÉm nƒÉng l·ª±c = {result['nang_luc_score']}, "
                                    f"ƒêi·ªÉm thi THPT quy ƒë·ªïi = {result['thpt_test_converted']}, "
                                    f"ƒêi·ªÉm h·ªçc b·∫° quy ƒë·ªïi = {result['hocba_converted']}")
                        elif tool_name == "calculate_bonus":
                            return f"ƒêi·ªÉm c·ªông: {result['bonus']}"
                        elif tool_name == "calculate_priority":
                            return f"ƒêi·ªÉm ∆∞u ti√™n: {result['priority']}"
                        elif tool_name == "calculate_admission_score":
                            return (f"ƒêi·ªÉm x√©t tuy·ªÉn: {result['admission_score']}\n"
                                    f"Chi ti·∫øt: ƒêi·ªÉm h·ªçc l·ª±c = {result['academic_score']}, "
                                    f"ƒêi·ªÉm nƒÉng l·ª±c = {result['nang_luc_score']}, "
                                    f"ƒêi·ªÉm thi THPT quy ƒë·ªïi = {result['thpt_test_converted']}, "
                                    f"ƒêi·ªÉm h·ªçc b·∫° quy ƒë·ªïi = {result['hocba_converted']}, "
                                    f"ƒêi·ªÉm c·ªông = {result['bonus']}, "
                                    f"ƒêi·ªÉm ∆∞u ti√™n = {result['priority']}")
                    else:
                        return (f"L·ªói: Vui l√≤ng cung c·∫•p ƒë·ªß th√¥ng tin cho {tool_name}. "
                                f"Y√™u c·∫ßu: {', '.join(required_params)}. "
                                f"V√≠ d·ª•: '{tool.description.split('.')[0]}'.")
                except Exception as e:
                    return f"L·ªói khi g·ªçi tool: {str(e)}"
        return f"Kh√¥ng t√¨m th·∫•y tool: {tool_name}"
    else:
        return "Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c c√¥ng c·ª•. Vui l√≤ng ki·ªÉm tra c√¢u h·ªèi. V√≠ d·ª•: 'T√≠nh ƒëi·ªÉm x√©t tuy·ªÉn v·ªõi ƒëi·ªÉm To√°n 8, t·ªïng c√°c m√¥n kh√°c 15, t·ªïng ƒëi·ªÉm thi THPT 24, trung b√¨nh 3 nƒÉm 8, ƒëi·ªÉm th√†nh t√≠ch 5, ƒëi·ªÉm ∆∞u ti√™n nh√≥m 2'."
# Prompt template cho intent classification
intent_prompt_template = """
B·∫°n l√† m·ªôt chatbot h·ªó tr·ª£ t∆∞ v·∫•n tuy·ªÉn sinh. Ph√¢n lo·∫°i √Ω ƒë·ªãnh (intent) c·ªßa c√¢u h·ªèi sau th√†nh m·ªôt trong ba lo·∫°i:
- `auto_chunk`: C√¢u h·ªèi li√™n quan ƒë·∫øn th√¥ng tin t·ª´ PDF, nh∆∞ quy ƒë·ªãnh, quy tr√¨nh x√©t tuy·ªÉn.
- `manual_chunk`: C√¢u h·ªèi li√™n quan ƒë·∫øn th√¥ng tin t·ª´ danh s√°ch Excel, nh∆∞ ti√™u ch√≠, danh m·ª•c c·ª• th·ªÉ.
- `calculate_score`: C√¢u h·ªèi y√™u c·∫ßu t√≠nh ƒëi·ªÉm x√©t tuy·ªÉn ho·∫∑c c√°c ƒëi·ªÉm th√†nh ph·∫ßn (nh∆∞ ƒëi·ªÉm nƒÉng l·ª±c, h·ªçc b·∫°, ∆∞u ti√™n).

C√¢u h·ªèi: "{query}"

**Output**:
Ch·ªâ tr·∫£ v·ªÅ t√™n intent (`auto_chunk`, `manual_chunk`, ho·∫∑c `calculate_score`). Kh√¥ng gi·∫£i th√≠ch.
"""
# G·∫Øn tools v√†o model
llm_with_tools = llm.bind_tools(tools)
def classify_intent(query: str) -> str:
    # T·∫°o n·ªôi dung message theo ƒë·ªãnh d·∫°ng chu·∫©n c·ªßa langchain
    prompt = intent_prompt_template.format(query=query)
    messages = [HumanMessage(content=prompt)]

    # G·ªçi m√¥ h√¨nh
    response = llm_with_tools.invoke(messages)

    # Truy c·∫≠p n·ªôi dung t·ª´ response (d√πng .content v√¨ response l√† AIMessage)
    if isinstance(response, AIMessage) and response.content:
        return response.content.strip()
    return "unknown"
def process_query(query: str, llm_with_tools) -> str:
    # 1. Ph√¢n lo·∫°i intent
    intent = classify_intent(query)

    # 2. X·ª≠ l√Ω theo intent
    if intent == "auto_chunk":
        # Truy v·∫•n pdf_collection
        results = query_chroma(pdf_collection, query)
        print(results)
        if results:
          msgs = [
            {"author": "system", "content": f"T√¥i l√† tr·ª£ l√Ω PDF. Th√¥ng tin:\n{results}"},
            {"author": "user",   "content": query},
        ]
        return llm.predict(msgs).strip()
        return "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong PDF."

    elif intent == "manual_chunk":
        # Truy v·∫•n excel_collection
        results = query_chroma(excel_collection, query)
        print(results)
        if results:
          msgs = [
            {"author": "system", "content": f"T√¥i l√† tr·ª£ l√Ω PDF. Th√¥ng tin:\n{results}"},
            {"author": "user",   "content": query},
        ]
        return llm.predict(msgs).strip()
        return "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong Excel."
    elif intent == "calculate_score":
        return  process_function_call(query, llm_with_tools)
    return "Kh√¥ng hi·ªÉu c√¢u h·ªèi. Vui l√≤ng h·ªèi l·∫°i."
if __name__ == "__main__":
    print("üåü Ch√†o b·∫°n! G√µ 'exit' ho·∫∑c 'quit' ƒë·ªÉ k·∫øt th√∫c phi√™n l√†m vi·ªác.\n")
    while True:
        query = input("B·∫°n: ").strip()
        if query.lower() in ("exit", "quit"):
            print("Chatbot: H·∫πn g·∫∑p l·∫°i! üëã")
            break

        # 1. Ph√¢n lo·∫°i intent
        intent = classify_intent(query)
        # 2. X·ª≠ l√Ω theo intent
        if intent == "auto_chunk":
            results = query_chroma(pdf_collection, query)
            if results:
                msgs = [
                    {"author": "system", "content": f"T√¥i l√† tr·ª£ l√Ω PDF. Th√¥ng tin:\n{results}"},
                    {"author": "user",   "content": query},
                ]
                answer = llm.predict(msgs).strip()
            else:
                answer = "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong PDF."
        elif intent == "manual_chunk":
            results = query_chroma(excel_collection, query)
            if results:
                msgs = [
                    {"author": "system", "content": f"T√¥i l√† tr·ª£ l√Ω Excel. Th√¥ng tin:\n{results}"},
                    {"author": "user",   "content": query},
                ]
                answer = llm.predict(msgs).strip()
            else:
                answer = "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong Excel."
        elif intent == "calculate_score":
            answer = process_function_call(query, llm_with_tools)
        else:
            answer = "Kh√¥ng hi·ªÉu c√¢u h·ªèi. Vui l√≤ng h·ªèi l·∫°i."

        print(f"Chatbot: {answer}\n")
